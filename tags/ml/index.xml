<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on MlSense</title>
    <link>https://mlsense.github.io/tags/ml/</link>
    <description>Recent content in ML on MlSense</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Nov 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://mlsense.github.io/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Common docker commands</title>
      <link>https://mlsense.github.io/posts/common_docker_commands/</link>
      <pubDate>Thu, 23 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/common_docker_commands/</guid>
      <description>I recently got to know about dockers. And I love it. For those who don&amp;rsquo;t know what dockers are. Here it is. Dockers help in software development in isolated frameworks.
Say, you are building an application named epsilon-X. epsilon-X relies on packages like numpy, scipy, pandas, other services, and software. Either you install each of these packages on your machine or you create an environment that has all these required packages along with the suitable versions.</description>
    </item>
    
    <item>
      <title>How to choose the probability cut-off in classification problem</title>
      <link>https://mlsense.github.io/posts/choosing_probability_cut_off_classification/</link>
      <pubDate>Thu, 18 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/choosing_probability_cut_off_classification/</guid>
      <description>Yesterday, I was taking a session on Data Science for few of my colleagues. The aim was to give a brief overview of machine learning. There were two of us taking the session. We had a rough idea what all we wanted to cover in the two hours session. I started the session starting with what machine learning is. The types of learning - supervised and unsupervised and the examples that fall into each of these.</description>
    </item>
    
    <item>
      <title>Tutorial on dplyr- a package for data manipulation in R</title>
      <link>https://mlsense.github.io/posts/tutorial_on_dplyr/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/tutorial_on_dplyr/</guid>
      <description>R is the most used tool in data science. It has no dearth of packages for specific use cases. There are three packages that I feel can get your most of the work done - ggplot2, dplyr, data.table.  ggplot2- Used for visualization. Also known as grammar of graphics. This package is used to plot graphs. The syntax is intuitive and easy to learn.
 dplyr- Used for data manipulation.</description>
    </item>
    
    <item>
      <title>The essence of machine learning is function estimation</title>
      <link>https://mlsense.github.io/posts/machine_learning_function_estimation/</link>
      <pubDate>Fri, 12 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/machine_learning_function_estimation/</guid>
      <description>Machine learning is cool. There is no denying in that. In this post we will try to make it a little uncool, well it will still be cool but you may start looking at it differently. Machine learning is not a black box. It is intuitive and this post is just to convey that. If I give you this function f(x) = x^2 + log(x) and ask to you tell me what will be f(2), you will first laugh at me and then run away to do something important.</description>
    </item>
    
    <item>
      <title>Time series and forecasting using R</title>
      <link>https://mlsense.github.io/posts/time_series_basics/</link>
      <pubDate>Wed, 03 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/time_series_basics/</guid>
      <description>Time series forecasting is a skill that few people claim to know. Machine learning is cool. And there are a lot of people interested in becoming a machine learning expert. But forecasting is something that is a little domain specific. Retailers like Walmart, Target use forecasting systems and tools to replenish their products in the stores. An excellent forecast system helps in winning the other pipelines of the supply chain.</description>
    </item>
    
    <item>
      <title>Diving into H2O with R</title>
      <link>https://mlsense.github.io/posts/h2o_with_r/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/h2o_with_r/</guid>
      <description>The problem Do you understand the pain when you have to train advanced machine learning algorithms like Random Forest on huge datasets? When there is a factor column that has way too many number of levels? When the time taken to train the model is so huge that you went to your pantry for snacks and came back, you are even done browsing 9gag but your model is still training, the code is still running?</description>
    </item>
    
    <item>
      <title>An illustrated introduction to adversarial validation - part 2</title>
      <link>https://mlsense.github.io/posts/introduction_to_adversarial_validation_part2/</link>
      <pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/introduction_to_adversarial_validation_part2/</guid>
      <description>In the last post we talked about the idea of adversarial validation and how it helps the problem when your validation set result doesn&amp;rsquo;t comply with that of test set result. In this post, I will share the R code to help achieve the idea of adversarial validation. The data used would be from Numerai competition. Loading required packages library(randomForest) library(glmnet) library(data.table) library(MLmetrics) getwd() dir() Reading train and test data set train &amp;lt;- fread(&amp;#34;Data/numerai_training_data.</description>
    </item>
    
    <item>
      <title>An illustrated introduction to adversarial validation - part 1</title>
      <link>https://mlsense.github.io/posts/introduction_to_adversarial_validation_part1/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/introduction_to_adversarial_validation_part1/</guid>
      <description>You&amp;rsquo;d have heard about cross-validation - a common technique used in data-science process to avoid overfitting and many a times to tune the optimal parameters. Overfitting is when the model does well on training data but fails drastically on test data. The reason could be one of the following:
 The model is trying to map the exact findings of training data to test data instead of generalizing the patterns.</description>
    </item>
    
    <item>
      <title>How to use Git andÂ Github</title>
      <link>https://mlsense.github.io/posts/introduction_to_adversarial_validation/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/introduction_to_adversarial_validation/</guid>
      <description>I had taken this course - How to use git and github some time last year. This post is an amalgamation of the course notes and other tutorials I have completed in understanding git. I will talk about the most frequently used commands. If you already are confident of your git skills and wants more of practical tutorial, you should head to this post - git and github for data scientists.</description>
    </item>
    
    <item>
      <title>The curse of bias and variance</title>
      <link>https://mlsense.github.io/posts/the_curse_of_bias_and_variance/</link>
      <pubDate>Wed, 08 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/the_curse_of_bias_and_variance/</guid>
      <description>Statistics is the field of study where we try to draw conclusions about the population from a sample. Why do we talk about sample? Why can&amp;rsquo;t we get the conclusions about the population directly from the population? Let me illustrate this by an example. Let us say we want to understand which brand of beer do the people of Bangalore prefers? An interesting question. If I ask you this question, how would you approach this problem?</description>
    </item>
    
    <item>
      <title>Random Forest explained intuitively</title>
      <link>https://mlsense.github.io/posts/random_forest_explained_intuitively/</link>
      <pubDate>Tue, 18 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/random_forest_explained_intuitively/</guid>
      <description>A little fun fact. The image that you see in this post was drawn by Professor Adele Cutler&amp;rsquo;s son. Professor Adele is has worked very closely with Prof. Breiman on Random forest. Prof. Breiman wanted a simple photo that captured the essence of simplicity and comprehensiveness of Random forest algorithm. Let us get started. Random Forests algorithm has always fascinated me. I like how this algorithm can be easily explained to anyone without much hassle.</description>
    </item>
    
    <item>
      <title>ROC and AUC - The three lettered acronyms</title>
      <link>https://mlsense.github.io/posts/roc_and_auc_three_letter_acronym/</link>
      <pubDate>Mon, 26 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/roc_and_auc_three_letter_acronym/</guid>
      <description>Confession time I don&amp;rsquo;t feel bad to confess this that ROC curve, AUC, True-positive and related terms took quite some time for me to understand. If today I contemplate on the reasons why I found this topic confusing. The first would be there are not many resources that explains intuitively what these mean. They just jump to the terms and the mathematical formula for them. The second being I had not used them even in my project work.</description>
    </item>
    
  </channel>
</rss>