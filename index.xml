<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MlSense</title>
    <link>https://mlsense.github.io/</link>
    <description>Recent content on MlSense</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 20 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://mlsense.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>https://mlsense.github.io/about/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/about/</guid>
      <description>I am a Data Scientist at Zeta Global building recommendation engines for media publishing houses. These days I am learning how recommendation engines work, exploring techniques like matrix factorization, factorization machines, and others. I have started using Python and I am loving it! I am a graduate from IIT Kharagpur with a Masters in Mathematics and Computing. I have picked up much of my understanding of machine learning at @WalmartLabs where I worked as Sr.</description>
    </item>
    
    <item>
      <title>Vim/Vi editor shortcuts</title>
      <link>https://mlsense.github.io/posts/vim_shortcuts/</link>
      <pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/vim_shortcuts/</guid>
      <description>Repetitive tasks should be done using as many shortcuts as possible. You are not doing anything new and hence not even an extra minute should be spent on doing the same. This post refers to the shortcuts that come in handy when working on the vi/vim editor.
This is not an exhaustive list. These are the ones I use frequently. Feel free to comment down your favorite shortcuts. Navigation keys  0 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Moves cursor to the start of the line $ &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Moves cursor to the end of the line w &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Moves forward one word b &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Moves backward one word</description>
    </item>
    
    <item>
      <title>My First Hugo Post</title>
      <link>https://mlsense.github.io/posts/my-first-hugo-post/</link>
      <pubDate>Wed, 17 Apr 2019 16:56:04 +0530</pubDate>
      
      <guid>https://mlsense.github.io/posts/my-first-hugo-post/</guid>
      <description> Hello world,
I am trying to create a site using Hugo static site generator. This is a markdown page.
Trying color syntaxing using pygmentize import numpy as np import pandas as pd import matplotlip.pyplot as plt import seaborn as sns # Add comment here  Using hugo syntax highlight # Loading required packages import numpy as np import pandas as pd import matplotlip.pyplot as plt import seaborn as sns </description>
    </item>
    
    <item>
      <title>Types of data in recommender systems</title>
      <link>https://mlsense.github.io/posts/types_of_data_recommender_system/</link>
      <pubDate>Thu, 27 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/types_of_data_recommender_system/</guid>
      <description>There are two ways in which we can collect data for building recommender systems — explicit and implicit. In this post, we will talk about both types of data, their characteristics and the challenges with them. Explicit feedback datasets The dictionary meaning of explicit is to state clearly and in detail. Explicit feedback data as the name suggests is an exact number given by a user to a product. Some of the examples of explicit feedback are ratings of movies by users on Netflix, ratings of products by users on Amazon.</description>
    </item>
    
    <item>
      <title>Time series and forecasting using R</title>
      <link>https://mlsense.github.io/posts/2017-05-03-time-series-forecasting/</link>
      <pubDate>Wed, 03 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/2017-05-03-time-series-forecasting/</guid>
      <description>Time series forecasting is a skill that few people claim to know. Machine learning is cool. And there are a lot of people interested in becoming a machine learning expert. But forecasting is something that is a little domain specific. Retailers like Walmart, Target use forecasting systems and tools to replenish their products in the stores. An excellent forecast system helps in winning the other pipelines of the supply chain.</description>
    </item>
    
    <item>
      <title>Diving into H2O with R</title>
      <link>https://mlsense.github.io/posts/h2o_with_r/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/h2o_with_r/</guid>
      <description>The problem Do you understand the pain when you have to train advanced machine learning algorithms like Random Forest on huge datasets? When there is a factor column that has way too many number of levels? When the time taken to train the model is so huge that you went to your pantry for snacks and came back, you are even done browsing 9gag but your model is still training, the code is still running?</description>
    </item>
    
    <item>
      <title>An illustrated introduction to adversarial validation - part 2</title>
      <link>https://mlsense.github.io/posts/introduction_to_adversarial_validation_part2/</link>
      <pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/introduction_to_adversarial_validation_part2/</guid>
      <description>In the last post we talked about the idea of adversarial validation and how it helps the problem when your validation set result doesn&amp;rsquo;t comply with that of test set result. In this post, I will share the R code to help achieve the idea of adversarial validation. The data used would be from Numerai competition. Loading required packages library(randomForest) library(glmnet) library(data.table) library(MLmetrics) getwd() dir() 
Reading train and test data set train &amp;lt;- fread(&amp;#34;Data/numerai_training_data.</description>
    </item>
    
    <item>
      <title>An illustrated introduction to adversarial validation - part 1</title>
      <link>https://mlsense.github.io/posts/introduction_to_adversarial_validation_part1/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/introduction_to_adversarial_validation_part1/</guid>
      <description>You&amp;rsquo;d have heard about cross-validation - a common technique used in data-science process to avoid overfitting and many a times to tune the optimal parameters. Overfitting is when the model does well on training data but fails drastically on test data. The reason could be one of the following:
 The model is trying to map the exact findings of training data to test data instead of generalizing the patterns.</description>
    </item>
    
    <item>
      <title>How to use Git and Github</title>
      <link>https://mlsense.github.io/posts/introduction_to_adversarial_validation/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/introduction_to_adversarial_validation/</guid>
      <description>I had taken this course - How to use git and github some time last year. This post is an amalgamation of the course notes and other tutorials I have completed in understanding git. I will talk about the most frequently used commands. If you already are confident of your git skills and wants more of practical tutorial, you should head to this post - git and github for data scientists.</description>
    </item>
    
    <item>
      <title>The curse of bias and variance</title>
      <link>https://mlsense.github.io/posts/the_curse_of_bias_and_variance/</link>
      <pubDate>Wed, 08 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/the_curse_of_bias_and_variance/</guid>
      <description>Statistics is the field of study where we try to draw conclusions about the population from a sample. Why do we talk about sample? Why can&amp;rsquo;t we get the conclusions about the population directly from the population? Let me illustrate this by an example. Let us say we want to understand which brand of beer do the people of Bangalore prefers? An interesting question. If I ask you this question, how would you approach this problem?</description>
    </item>
    
    <item>
      <title>Visualisation in machine learning is under-rated</title>
      <link>https://mlsense.github.io/posts/visualisation_is_under-rated/</link>
      <pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/visualisation_is_under-rated/</guid>
      <description>Visualisation is one of the most important pillars of data science. Every one wants to learn Machine learning but if you explain them the little tasks that involve the overall workflow of the process, it turns them off. Everyone just wants to do the cool stuff. They want to build models and be done with it. And I was one of them. I understand that feeling when you get the data and without much understanding of the features in the dataset, we just want to throw in the data to a model and hope that something good comes out.</description>
    </item>
    
    <item>
      <title>Random Forest explained intuitively</title>
      <link>https://mlsense.github.io/posts/random_forest_explained_intuitively/</link>
      <pubDate>Tue, 18 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/random_forest_explained_intuitively/</guid>
      <description>A little fun fact. The image that you see in this post was drawn by Professor Adele Cutler&amp;rsquo;s son. Professor Adele is has worked very closely with Prof. Breiman on Random forest. Prof. Breiman wanted a simple photo that captured the essence of simplicity and comprehensiveness of Random forest algorithm. Let us get started. Random Forests algorithm has always fascinated me. I like how this algorithm can be easily explained to anyone without much hassle.</description>
    </item>
    
    <item>
      <title>Improve runtime of Random Forest in R</title>
      <link>https://mlsense.github.io/posts/improve_runtime_random_forest_r/</link>
      <pubDate>Thu, 13 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/improve_runtime_random_forest_r/</guid>
      <description>There are two ways one can write the code to train a random forest model in R. Both the ways are listed below. A normal and frequent way of writing the command to train the random forest model is something like this. rfModel &amp;lt;- randomForest(Survived~. , data = trainSample[, -c(6, 8, 9)])  Notice the ~ sign. We call this the formula way of writing. Another way of writing the command to train the random forest model is shown below.</description>
    </item>
    
    <item>
      <title>How to install a package of a particular version in R</title>
      <link>https://mlsense.github.io/posts/install_a_package_particular_version_in_r/</link>
      <pubDate>Wed, 05 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/install_a_package_particular_version_in_r/</guid>
      <description>I recently tried installing caret package in R using install.packages(&amp;lsquo;caret&amp;rsquo;, dependencies=T) 
Normally this installation of package works and I continue to work with the functions associated with the package. When I tried including the package using library(caret) 
I got the following error.
Error in loadNamespace(j  R was not able to install this dependency package- pbkrtest. So I tried installing it separately, again using install.package(&amp;lsquo;pbkrtest&amp;rsquo;, dependencies=T)</description>
    </item>
    
    <item>
      <title>Shell commands come in handy for a data scientist</title>
      <link>https://mlsense.github.io/posts/shell_commands_for_data_scientist/</link>
      <pubDate>Fri, 30 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/shell_commands_for_data_scientist/</guid>
      <description>I am no expert of shell commands. I have been using them for quite some time and thought I give an attempt to list down the most common commands. I am writing these mostly from the perspective of a data-science guy. Let us get started. I will use the file- ‘data.txt’ to illustrate these commands. ‘data.txt’ is a file having 200 rows and 8 columns. You can access the data here.</description>
    </item>
    
    <item>
      <title>ROC and AUC - The three lettered acronyms</title>
      <link>https://mlsense.github.io/posts/roc_and_auc_three_letter_acronym/</link>
      <pubDate>Mon, 26 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/roc_and_auc_three_letter_acronym/</guid>
      <description>Confession time I don&amp;rsquo;t feel bad to confess this that ROC curve, AUC, True-positive and related terms took quite some time for me to understand. If today I contemplate on the reasons why I found this topic confusing. The first would be there are not many resources that explains intuitively what these mean. They just jump to the terms and the mathematical formula for them. The second being I had not used them even in my project work.</description>
    </item>
    
    <item>
      <title>Hadoop Streaming</title>
      <link>https://mlsense.github.io/posts/hadoop_streaming/</link>
      <pubDate>Mon, 29 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/hadoop_streaming/</guid>
      <description>A few days ago, I had written a post on The Big Data Problem{:target=&amp;rdquo;_blank&amp;rdquo;} which attempted to understand why we need big data and what the fuss is all about. You may want to read it here{:target=&amp;rdquo;_blank&amp;rdquo;}. Having understood why we need big data, let’s understand how we can go about analyzing the same. What is the way out to do analysis on big data? The solution is Streaming…Hadoop Streaming.</description>
    </item>
    
    <item>
      <title>When R package is not available across the cluster</title>
      <link>https://mlsense.github.io/posts/r_packages_not_installed_cluster/</link>
      <pubDate>Tue, 02 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/r_packages_not_installed_cluster/</guid>
      <description>When deploying R codes across the cluster, many a times the reason for the failure of the task is unavailability of a particular package across all nodes of the cluster. We wait for someone to get the package installed across all the nodes. This may take some days. Do we wait for them? Naah! Presenting a temporary solution that one of my colleague came up with. I have used this technique and this works smoothly.</description>
    </item>
    
    <item>
      <title>The Big Data Problem</title>
      <link>https://mlsense.github.io/posts/big_data_problem/</link>
      <pubDate>Wed, 29 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/big_data_problem/</guid>
      <description>Big data has become a sensation these days. Anyone and everyone wants to use this in their discussions. When I was still in my college and preparing for campus placements, I had attended almost all the pre-placement talks that companies gave to its prospective candidates. American Express was one such company that had talked extensively about big data and hadoop in their presentation. I remember clearly, the blank faces that all of us had.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://mlsense.github.io/posts/2017-05-12-ml-function-estimation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/2017-05-12-ml-function-estimation/</guid>
      <description>Title: The essence of machine learning is function estimation date: 2017-05-12 8:00 comments: true slug: machine_learning_function_estimation Category: ML, Data Science Tags: machine-learning, tutorial, manish barnwal description: This post talks explains how the essence of machine learning is function estimation. Keywords: ML, data science, machine learning explained, manish barnwal
Machine learning is cool. There is no denying in that. In this post we will try to make it a little uncool, well it will still be cool but you may start looking at it differently.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://mlsense.github.io/posts/2017-05-15-dplyr-tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/2017-05-15-dplyr-tutorial/</guid>
      <description>Title: Tutorial on dplyr- a package for data manipulation in R date: 2017-05-15 8:00 comments: true slug: tutorial_on_dplyr Category: ML, Data Science Tags: tutorial, R, machine-learning, manish barnwal description: This post is a tutorial on dplyr - a package for data manipulation in R. Keywords: dplyr, dplyr tutorial, dplyr package, R, data manipulation, manish barnwal
R is the most used tool in data science. It has no dearth of packages for specific use cases.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://mlsense.github.io/posts/2017-05-18-choosing-probability-cut-off-in-classification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/2017-05-18-choosing-probability-cut-off-in-classification/</guid>
      <description>Title: How to choose the probability cut-off in classification problem date: 2017-05-18 8:00 comments: true slug: choosing_probability_cut-off_in_classification Category: ML, Data Science Tags: machine-learning, tutorial, manish barnwal description: This post describes how to choose the probability cut-off in classification problem. Keywords: ML, data science, R, classification, probability, cut-off, machine learning, manish barnwal
Yesterday, I was taking a session on Data Science for few of my colleagues. The aim was to give a brief overview of machine learning.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://mlsense.github.io/posts/2017-11-23-docker-commands/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/2017-11-23-docker-commands/</guid>
      <description>Title: Common docker commands date: 2017-11-23 8:00 comments: true slug: common_docker_commands Category: ML, Data Science Tags: machine-learning, tutorial, hacks, manish barnwal description: This post is a tutorial on the commonly used docker commands. Keywords: docker, docker-commands, docker tutorial, manish barnwal
I recently got to know about dockers. And I love it. For those who don&amp;rsquo;t know what dockers are. Here it is. Dockers help in software development in isolated frameworks.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://mlsense.github.io/posts/2018-01-23-creating-virtual-env/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/2018-01-23-creating-virtual-env/</guid>
      <description>Title: Creating a virtual environment in Python date: 2018-01-23 8:00 comments: true slug: virtual_environment_in_python Category: ML, Data Science Tags: python, tutorial, hacks, manish barnwal description: This is a tutorial on how to create a virtual environment in Python. Keywords: virtual environment, python, tutorial, manish barnwal
I was trying to get a virtual environment set up on Python 3 using mkvirtualenv but somehow the virtual environment was getting created on Python 2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://mlsense.github.io/posts/2018-04-18-git-and-github-for-data-scientists/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/2018-04-18-git-and-github-for-data-scientists/</guid>
      <description>Title: git and github for data scientists date: 2018-04-18 8:00 comments: true slug: git_and_github_for_data_scientists Category: ML, Data Science Tags: python, tutorial, hacks, manish barnwal description: This is a tutorial on git and github for anyone who wants to use it. Keywords: git, github, tutorial, manish barnwal
It has been close to a year since I shifted to a start-up which incidentally got acquired after a month of my joining. Before this I used to work at WalmartLabs where we always wanted to use a version control system like git but it never took off properly.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://mlsense.github.io/posts/2018-06-18-dates-in-python/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mlsense.github.io/posts/2018-06-18-dates-in-python/</guid>
      <description>Title: Working with dates in Python date: 2018-06-18 8:00 comments: true slug: working_with_dates_in_python Category: ML, Data Science Tags: python, tutorial, hacks, manish barnwal description: This tutorial is on ways to deal with dates in Python. Keywords: date, datetime, python, tutorial, manish barnwal
I cringe every time I see a date type column in the data. And you may ask why so? Date columns need some methods applied to them
The reason is I don&amp;rsquo;t normally see date columns in the data I work with so I don&amp;rsquo;t remember the functions and methods that work on dates to get meaningful columns out of the date column in the data.</description>
    </item>
    
  </channel>
</rss>